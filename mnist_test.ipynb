{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL.Image as PILImage\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "from src.hyperparameters import *\n",
    "from src.models import *\n",
    "from src.utils import *\n",
    "import src.mnist_preprocess\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Joel Bartlett\\OneDrive\\5 Zone\\Synthetic Data\\synthetic-age-data\\src\\mnist_preprocess.py:14: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\Joel Bartlett\\Miniconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\Joel Bartlett\\Miniconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Joel Bartlett\\Miniconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting mnist\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Joel Bartlett\\Miniconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting mnist\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\Joel Bartlett\\Miniconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "(55000, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "data = src.mnist_preprocess.load_mnist_color()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Joel Bartlett\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.Session()\n",
    "\n",
    "real_data_placeholder = tf.placeholder('float', shape=[batch_size, image_size, image_size, 3])\n",
    "z_placeholder = tf.placeholder(tf.float32, [batch_size, noise_dimension])\n",
    "\n",
    "disc_output_real = forward_pass_discriminator(real_data_placeholder)\n",
    "gen_output = forward_pass_generator(z_placeholder)\n",
    "disc_output_fake = forward_pass_discriminator(gen_output, reuse='False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'discriminator_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-70be41e1d6b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mreal_image_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml1_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_data_placeholder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisc_output_real\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfake_image_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ml1_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisc_output_fake\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdiscriminator_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdiscriminator_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_image_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake_image_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkt_equilbrium_term\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mgenerator_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfake_image_loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mkt_p\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkt_equilbrium_term\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlambda_kt_learning_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma_diversity_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreal_images_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfake_images_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'discriminator_loss' is not defined"
     ]
    }
   ],
   "source": [
    "real_image_loss = l1_loss(real_data_placeholder, disc_output_real)\n",
    "fake_image_loss = l1_loss(gen_output, disc_output_fake)\n",
    "discriminator_loss = discriminator_loss(real_image_loss, fake_image_loss, kt_equilbrium_term)\n",
    "generator_loss = fake_image_loss\n",
    "kt_p = kt_step(kt_equilbrium_term, lambda_kt_learning_rate, gamma_diversity_ratio, real_images_loss, fake_images_loss)\n",
    "convergence = convergence(real_image_loss, fake_image_loss, gamma_diversity_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "disc_vars = [var for var in tvars if 'dec' in var.name]\n",
    "gen_vars = [var for var in tvars if 'gen' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.train.AdamOptimizer(learning_rate)\n",
    "dis_opt = adam.minimize(discriminator_loss, var_list=disc_vars)\n",
    "gen_opt = adam.minimize(generator_loss, var_list=gen_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "iterations=1\n",
    "for i in range(iterations):\n",
    "    z_batch = np.random.uniform(-1,1,size=[batch_size, noise_dimension])\n",
    "    \n",
    "    start_batch = i*batch_size\n",
    "    end_batch = start_batch+batch_size\n",
    "    real_image_batch = data[start_batch:end_batch, :,:,:]\n",
    "    \n",
    "    _, total_disc_loss=sess.run([dis_opt, discriminator_loss], feed_dict={z_placeholder: z_batch, real_data_placeholder: real_image_batch})\n",
    "    _, total_gen_loss=sess.run([gen_opt, generator_loss], feed_dict={z_placeholder: z_batch})\n",
    "    \n",
    "    m_global = sess.run([convergence], feed_dict={z_placeholder: z_batch, real_data_placeholder: real_image_batch})\n",
    "    \n",
    "    print(\"Step: {}, Convergence: {} ,Discriminator Loss: {}, Generator Loss {}\".format(i, m_global, total_disc_loss, total_gen_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image=forward_pass_generator(z_placeholder, reuse=True)\n",
    "z_batch = np.random.uniform(-1,1,size=[16, noise_dimension])\n",
    "temp = (sess.run(sample_image, feed_dict={z_placeholder: z_batch}))\n",
    "# my_i = temp.squeeze()\n",
    "plt.imshow(temp[2])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
